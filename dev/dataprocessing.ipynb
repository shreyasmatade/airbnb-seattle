{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initial data lookup\n",
    "def get_shape(df):\n",
    "    print('The shape of the dataframe is : '+ str(df.shape))\n",
    "    \n",
    "def get_head(df, rows = 5):\n",
    "    print(\"########################################################################\")\n",
    "    print(df.head(rows))\n",
    "    \n",
    "# Missing Values\n",
    "def get_missing_values_by_column(df):\n",
    "    all_cols = df.columns.values\n",
    "    print(all_cols)\n",
    "    for col in all_cols:\n",
    "        missing_percent = df[col].isnull().mean()\n",
    "        if missing_percent > 0:\n",
    "            print(\"Column \" + col + \" has \" + str(float(\"{0:.2f}\".format(missing_percent * 100))) + \"% missing values\" )\n",
    "            \n",
    "def get_float_val (df):\n",
    "    df.replace(regex=True,inplace=True,to_replace='[^a-zA-Z0-9\\n\\.]',value='')\n",
    "    df = df.astype(dtype='float')\n",
    "    # since host left it blank..replacing null values with 0 \n",
    "    return df.fillna(value = 0).copy()\n",
    "\n",
    "def get_bool_val (df):\n",
    "    df.replace(['t','f'],[1,0],inplace=True)\n",
    "    df = df.astype(dtype='bool')\n",
    "    # since host left it blank..replacing null values with 0 \n",
    "    return df.fillna(value = 0).copy()\n",
    "\n",
    "\n",
    "def count_days_since(oldDate, currentDate = datetime(2016,1,1,0,0,0)):\n",
    "    return (currentDate-oldDate).days\n",
    "\n",
    "\n",
    "def preprocess_features(df):\n",
    "    '''\n",
    "    From looking at each of the categorical variable we found that,\n",
    "    1. experiences_offered, host_verifications, market, has_availability, requires_license columns has only one value hence we need to Drop these columns from dataframe.\n",
    "    2. 'security_deposit', 'cleaning_fee', 'extra_people' these columns need to be converted to float value of $\n",
    "    3. amenities need to converted to int where number is total number of amenities\n",
    "    4. host_response_rate need to converted to float\n",
    "    5. Transit need to converted to nminal var where NaN = 0 and everuthing else is 1\n",
    "    6. host_since need to converted to diff between 01/01/2016 - host_since in days\n",
    "\n",
    "    '''\n",
    "    # Convert string to Float for 'security_deposit', 'cleaning_fee', 'extra_people',host_acceptance_rate\n",
    "    df['host_acceptance_rate'] = get_float_val(df['host_acceptance_rate'])\n",
    "    df['host_response_rate'] = get_float_val(df['host_response_rate'])\n",
    "    df['security_deposit'] = get_float_val(df['security_deposit'])\n",
    "    df['cleaning_fee'] = get_float_val(df['cleaning_fee'])\n",
    "    df['extra_people'] = get_float_val(df['extra_people'])\n",
    "    df['price'] = get_float_val(df['price'])  # there are no missing values here\n",
    "    \n",
    "    # Create Transit_available variable from transit and drop null rows\n",
    "    df['Transit_available'] = ~ (df.transit.isnull())\n",
    "    df = df.drop(['transit'],axis=1);\n",
    "\n",
    "    # Create Facilities variable by counting number of facilities propvided\n",
    "    df['Facilities'] = df.amenities.apply(lambda a : len(a))\n",
    "    df = df.drop(['amenities'],axis=1);\n",
    "\n",
    "    # Create Host_experience variable, experience in days, from host_since\n",
    "    df['Host_experience'] = pd.to_datetime(df.host_since).apply(count_days_since)\n",
    "    df = df.drop(['host_since'],axis=1);\n",
    "    \n",
    "    # Convert string t,f variables in boolean variables\n",
    "    df['host_is_superhost'] = get_bool_val(df['host_is_superhost'])\n",
    "    df['require_guest_profile_picture'] = get_bool_val(df['require_guest_profile_picture'])\n",
    "    df['require_guest_phone_verification'] = get_bool_val(df['require_guest_phone_verification'])\n",
    "    df['host_has_profile_pic'] = get_bool_val(df['host_has_profile_pic'])\n",
    "    df['host_identity_verified'] = get_bool_val(df['host_identity_verified'])\n",
    "    df['is_location_exact'] = get_bool_val(df['is_location_exact'])\n",
    "    df['has_availability'] = get_bool_val (df['has_availability'])\n",
    "    df['instant_bookable'] = get_bool_val(df['instant_bookable'])\n",
    "    \n",
    "    # Clean unnecessary feature to reduce dimntionality experiences_offered, host_verifications, market, has_availability, requires_license\n",
    "    df = df.drop(['experiences_offered','host_verifications','market','has_availability','requires_license'],axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Lets impute data\n",
    "def impute_features(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    df - pandas dataframe with imputed data\n",
    "    \n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. For each numeric variable in X, fill the column with the mean value of the column.\n",
    "    2. Lets drop all the rows which has nan values.\n",
    "    3. Create dummy variables for categorical variables\n",
    "    '''\n",
    "   \n",
    "    # Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "    print(num_vars)\n",
    "    for col in num_vars:\n",
    "        df[col].fillna((df[col].mean()), inplace=True)\n",
    "        \n",
    "    # Dummy the categorical variables\n",
    "    cat_vars = df.select_dtypes(include=['object']).copy().columns\n",
    "    print(cat_vars)\n",
    "    for var in  cat_vars:\n",
    "        # for each cat add dummy var, drop original column\n",
    "        df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "    return df\n",
    "\n",
    "# Lets Split data as per target and features\n",
    "def split_data(df,target='price'):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    target - target var \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no target\n",
    "    2. Create X as all the columns that are not the target column\n",
    "    3. Create y as the target column\n",
    "    '''\n",
    "    # Drop rows with missing salary values\n",
    "    df = df.dropna(subset=[target], axis=0)\n",
    "    y = df[target]\n",
    "    \n",
    "    #Drop respondent and expected salary columns\n",
    "    df = df.drop([target], axis=1)\n",
    "    \n",
    "    X = df\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalise_data(df):   \n",
    "    # normalise data\n",
    "    scaler = MinMaxScaler().fit(df)\n",
    "    return scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangling(df,selected_vars,target='price'):\n",
    "\n",
    "    # remove irrelavant features from dataframe\n",
    "    df = df[selected_vars].copy()\n",
    "\n",
    "    # Preprocess the features as per required for analysis\n",
    "    df = preprocess_features(df)\n",
    "\n",
    "    # Null Values\n",
    "    df.columns[df.isnull().mean() > 0]\n",
    "\n",
    "    #Use the function impute all the Null, nan values\n",
    "    df = impute_features(df) \n",
    "\n",
    "    #Split data\n",
    "    X,y = split_data(df,target)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_target(df,feature,target):\n",
    "    '''\n",
    "    This function plots target vs feature plot\n",
    "    '''\n",
    "    df[target] = get_float_val(df[target])\n",
    "    df[target] = df[target].astype(dtype='float')\n",
    "    df = df.dropna(subset=[target],axis=0)\n",
    "    plotg = df.groupby([feature])[target].mean()\n",
    "    import matplotlib.pyplot as plt\n",
    "    _ = plotg.plot(kind='bar',figsize=(10,10),title='Mean '+target+' by ' +feature+ ' in Seattle 2016 airbnb',y= 'Mean '+target,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
